# -*- coding: utf-8 -*-
"""Code-Alpha_DS Task#1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G3sHykulxUdvrSWdgKGkBo7IrcYOXo0o
"""

# Step 1: Import the necessary libraries
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score
import numpy as np

# Step 2: Load the Iris dataset
iris = load_iris()
X = iris.data  # Features: sepal length, sepal width, petal length, petal width
y = iris.target  # Target: species (setosa: 0, versicolor: 1, virginica: 2)

# Step 3: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Preprocess the data (standardization)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Step 5: Train the KNN classifier
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)

# Step 6: Make predictions on the test set
y_pred = knn.predict(X_test)

# Step 7: Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Optional: Make predictions for new measurements
new_measurements = np.array([[10.1, 57.5, 43.4, 21.2],  # Example: Setosa
                              [70.0, 55.2, 98.0, 34.0],  # Example: Versicolor
                              [65.3, 35.3, 69.0, 2.5]])  # Example: Virginica

# Standardize the new measurements
new_measurements_scaled = scaler.transform(new_measurements)
predictions = knn.predict(new_measurements_scaled)

# Print the predicted species
for i, measurement in enumerate(new_measurements):
    print(f"Measurement: {measurement} -> Predicted species: {iris.target_names[predictions[i]]}")

# Step 1: Import the necessary libraries
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score
import numpy as np

# Step 2: Load the Iris dataset
iris = load_iris()
X = iris.data  # Features: sepal length, sepal width, petal length, petal width
y = iris.target  # Target: species (setosa: 0, versicolor: 1, virginica: 2)

# Step 3: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Train the Decision Tree classifier
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train, y_train)

# Step 5: Make predictions on the test set
y_pred = dt_classifier.predict(X_test)

# Step 6: Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Optional: Visualize the Decision Tree
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

plt.figure(figsize=(12, 8))
plot_tree(dt_classifier, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)
plt.title("Decision Tree for Iris Classification")
plt.show()

# Optional: Make predictions for new measurements
new_measurements = np.array([[10.1, 57.5, 43.4, 21.2],  # Example: Setosa
                              [70.0, 55.2, 98.0, 34.0],  # Example: Versicolor
                              [65.3, 35.3, 69.0, 2.5]])  # Example: Virginica

# Make predictions for new measurements
predictions = dt_classifier.predict(new_measurements)

# Print the predicted species
for i, measurement in enumerate(new_measurements):
    print(f"Measurement: {measurement} -> Predicted species: {iris.target_names[predictions[i]]}")